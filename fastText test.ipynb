{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Fasttext Supervised learning example \n",
    "\n",
    "This notebook is inspired by the [Supervised Learning fastText tutorial](https://github.com/facebookresearch/fastText/blob/master/tutorials/supervised-learning.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    \"\"\"\n",
    "    Read data 'line by line', using generators.\n",
    "    Generators make it easier to process BIG text files.\n",
    "    \"\"\"\n",
    "    with open(filename, 'r') as input:\n",
    "        for line in input:\n",
    "            yield line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_data(filename, data):\n",
    "    \"\"\"\n",
    "    Write result to a file.\n",
    "    \n",
    "    :param result: the list to be written to the file\n",
    "    \"\"\"\n",
    "    with open(filename, \"a\") as output:\n",
    "        output.write('{}\\n'.format(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def preprocess(data):\n",
    "    \"\"\"\n",
    "    Preprocess data, filtering out stopwords, punctuation and lowering \n",
    "    all splitted tokens.\n",
    "    \n",
    "    :param data: the string data to be processed\n",
    "    \"\"\"    \n",
    "    # Pad punctuation with spaces on both sides\n",
    "    for char in ['.', '\"', ',', '(', ')', '!', '?', ';', ':']:\n",
    "        data = data.replace(char, ' ' + char + ' ')\n",
    "    sw = stopwords.words('english')\n",
    "    splitted_chunks = data.split()\n",
    "    lowered_chunks = (item.lower() for item in splitted_chunks)\n",
    "    chunks_without_punctuation = (chunk for chunk in lowered_chunks if chunk not in punctuation)\n",
    "    chunks_without_stopwords = (chunk for chunk in chunks_without_punctuation if chunk not in sw)\n",
    "    return \" \".join(list(chunks_without_stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "\n",
    "def pipeline(input_filename, output_filename, limit=None):\n",
    "    \"\"\"\n",
    "    Iterate over the rows and apply the text preprocessing.\n",
    "\n",
    "    :param input_filename: name of the input filename\n",
    "    :param output_filename: name of the output filename\n",
    "    :param limit: get the first N rows\n",
    "    \"\"\"    \n",
    "    open(output_filename, 'w').close()  # Hack to \"reset\" the output file\n",
    "    for row in islice(read_data(input_filename), 0, limit):\n",
    "        data = preprocess(row)\n",
    "        if data:\n",
    "            write_data(output_filename, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_model(model, test_data):\n",
    "    result = model.test(test_data)\n",
    "    print('Precision@1:', result.precision)\n",
    "    print('Recall@1:', result.recall)\n",
    "    print('Number of examples:', result.nexamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import path\n",
    "\n",
    "data_dir = path.join(path.dirname(\"__file__\"), 'data')\n",
    "enron_input = path.join(data_dir, 'recipient_data.txt')\n",
    "fairframe_test = path.join(data_dir, 'fairframe.train') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pipeline(cooking_input, cooking_input_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_results(N, p, r):\n",
    "    print(\"N\\t\" + str(N))\n",
    "    print(\"P@{}\\t{:.3f}\".format(1, p))\n",
    "    print(\"R@{}\\t{:.3f}\".format(1, r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def results(N, p, r):\n",
    "    return N, p, r\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import fastText as ft\n",
    "from fastText import train_supervised\n",
    "\n",
    "# Info to save the model\n",
    "model_dir = path.join(path.dirname(\"__file__\"), 'models')\n",
    "gender_output = path.join(model_dir, 'gender_classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_val = []\n",
    "precision = []\n",
    "recall = []\n",
    "for wordNgrams in range(5,10):\n",
    "    model = train_supervised(input=enron_input, \n",
    "                             epoch=50, #tuned \n",
    "                             lr=0.00001, \n",
    "                             ws = 2, #tuned \n",
    "                             wordNgrams=wordNgrams, #drops when you increase it \n",
    "                             verbose=10, \n",
    "                             minCount=1, \n",
    "                             dim=200)\n",
    "    N,p,r =  results(*model.test(fairframe_test))\n",
    "    N_val.append(N)\n",
    "    precision.append(p)\n",
    "    recall.append(r)\n",
    "\n",
    "#print_results(*model.test(cooking_test))  \n",
    "\n",
    "plt.plot(precision)\n",
    "plt.plot(recall)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not normalized input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalized input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load existing test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
